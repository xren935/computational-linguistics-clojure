\documentclass[10pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{url}
% use straight quotes in texttt environment, make 0 different from O
\usepackage[zerostyle=b,straightquotes,scaled=.93]{newtxtt}
\usepackage{hyperref}
\usepackage{listings}
\lstset{
 basicstyle=\ttfamily,
 columns=fullflexible,
 upquote,
 keepspaces,
 literate={*}{{\char42}}1
 {-}{{\char45}}1
}
\usepackage[short labels]{enumitem}

\usepackage{soul}  % for strike through (\st{})
\usepackage[dvipsnames,usenames,table]{xcolor} % for colors

\newcommand{\email}[1]{\href{mailto:#1}{\texttt{#1}}}
\newcommand{\PSnum}{3}

\begin{document}

\title{LING/COMP 445, LING 645\\Problem Set \PSnum}
\date{Due before 8:35 AM on Tuesday, October 20, 2020}
\maketitle
There are several types of questions below. 
\begin{itemize}
\item
For questions involving answers in English or mathematics or a
combination of the two, put your answers to the question in an
\textbf{Answer} section like in the example below. You can find more
information about \LaTeX{} here \url{https://www.latex-project.org/}.

\item For programming questions,
please put your answers into a file called
\texttt{ps\PSnum-lastname-firstname.clj}. Be careful to follow the instructions
exactly and be sure that all of your function definitions use the
precise names, number of inputs and input types, and output types as
requested in each question.

For the code portion of the assignment, \textbf{it is crucial to submit a
standalone file that runs}. Before you submit \texttt{ps\PSnum-lastname-firstname.clj}, 
make sure that your code executes correctly without any errors 
when run at the command line by typing 
\texttt{clojure ps\PSnum-lastname-firtname.clj} at a terminal
prompt. We cannot grade any code that does not run correctly as a
standalone file, and if the preceding command produces an error,
the code portion of the assignment will receive a $0$.

To do the computational problems, we recommend that you install
Clojure on your local machine and write and debug the answers to each
problem in a local copy of \texttt{ps\PSnum-lastname-firstname.clj}. You can
find information about installing and using Clojure here
\url{https://clojure.org/}.
\end{itemize}
Once you have entered your answers, please compile your copy of this
\LaTeX{} into a PDF and submit 
\begin{enumerate}[(i),noitemsep]
\item
the compiled PDF renamed to
\texttt{ps\PSnum-lastname-firstname.pdf} 
\item
the raw \LaTeX{} file renamed to
\texttt{ps\PSnum-lastname-firstname.tex} and 
\item
your \texttt{ps\PSnum-lastname-firstname.clj}
\end{enumerate}
to the Problem Set \PSnum{} folder under `Assignments' on MyCourses.

\noindent\hrulefill %--------------------------------

\paragraph{Example Problem:}
This is an example question using some fake math like this
$L=\sum_0^{\infty} \mathcal{G} \delta_x$.

\paragraph{Example Answer:} Put your answer right under the question like
this $L=\sum_0^{\infty} \mathcal{G} \delta_x$.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 1:}

In these exercises, we are going to be processing some natural
linguistic data, the first paragraph of Moby Dick. We will first write
some procedures that help us to manipulate this corpus. We will then
start analyzing this data using some probabilistic models.

We will start by defining the variable \texttt{moby-word-tokens},
which is a list containing all of the words from our corpus.

\begin{lstlisting}
(def moby-word-tokens '(CALL me Ishmael . Some years ago never mind
     how long precisely having little or no money in my purse , and
     nothing particular to interest me on shore , I thought I would
     sail about a little and see the watery part of the world .  It is
     a way I have of driving off the spleen , and regulating the
     circulation . Whenever I find myself growing grim about the mouth
     whenever it is a damp , drizzly November in my soul whenever I
     find myself involuntarily pausing before coffin warehouses , and
     bringing up the rear of every funeral I meet and especially
     whenever my hypos get such an upper hand of me , that it requires
     a strong moral principle to prevent me from deliberately stepping
     into the street , and methodically knocking people's hats off
     then , I account it high time to get to sea as soon as I can .
     This is my substitute for pistol and ball . With a philosophical
     flourish Cato throws himself upon his sword I quietly take to the
     ship .  There is nothing surprising in this . If they but knew it
     , almost all men in their degree , some time or other , cherish
     very nearly the same feelings toward the ocean with me .))
\end{lstlisting}

Below we have defined the function \texttt{member-of-list?}, which
takes two arguments, \texttt{w} and \texttt{l}. The function returns
\texttt{true} if the element \texttt{w} is a member of the list
\texttt{l}, and \texttt{false} otherwise. For example, if \texttt{w}
equals \texttt{'the} and \texttt{l} equals \texttt{(list 'the 'man
  'is)}, then the function will return \texttt{true}. In contrast, if
\texttt{w} equals \texttt{'the} and \texttt{l} equals \texttt{(list
  'man 'is)}, then the function will return false.

\begin{lstlisting}
(defn member-of-list? [w l]
  (if (empty? l)
    false
    (if (= w (first l))
      true
      (member-of-list? w (rest l)))))
\end{lstlisting}

Below we have defined the skeleton for the function
\texttt{get-vocabulary}. This function takes two arguments,
\texttt{word-tokens} and \texttt{vocab}. \texttt{word-tokens} is a
list of words, and the function should return the list of unique words
occurring in \texttt{word-tokens}. This list of unique words is called a
vocabulary. For example, if \texttt{word-tokens} is equal to 
\texttt{(list 'the 'man 'is 'man 'the)}, then get-vocabulary should 
return \texttt{(list 'the 'man 'is)}.

Fill in the missing parts of this function. When you call
\texttt{(get-vocabulary moby-word-tokens '())}, you will get back a
list of all of the unique words occurring in \texttt{moby-word-tokens}. Give
this the name \texttt{moby-vocab}.

\begin{lstlisting}
;;(defn get-vocabulary [word-tokens vocab]
;;  (if (empty? word-tokens)
;;      vocab
;;      (if (member-of-list? ;;finish this line
;;          (get-vocabulary ;;finish this line
;;          (get-vocabulary ;;finish this line
\end{lstlisting}

\paragraph{Answer 1:} Please see my answer in \texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 2:}

Define a function \texttt{get-count-of-word}. This function should
take three arguments, \texttt{w}, \texttt{word-tokens}, and
\texttt{count}. \texttt{w} is a word and \texttt{word-tokens} is a
list of words. When you call \texttt{(get-count-of-word w word-tokens
  0)}, the function should return the number of occurrences of the
word \texttt{w} in the list \texttt{word-tokens}. For example, if
word-tokens equals \texttt{(list 'the 'the 'man)}, and \texttt{w}
equals \texttt{'the}, then the function should return \texttt{2}. If
\texttt{word-tokens} is the same, but \texttt{w} equals \texttt{'man},
then the function should return \texttt{1}.

\begin{lstlisting}
;;(defn get-count-of-word [w word-tokens count]
  ;;fill this in
\end{lstlisting}

Below we have defined the function \texttt{get-word-counts}, which
takes two arguments, \texttt{vocab} and
\texttt{word-tokens}. \texttt{vocab} is assumed to be a list of the
unique words that occur in the list \texttt{word-tokens}. The function
returns the number of times each word in vocab occurs in
word-tokens. For example, suppose \texttt{vocab} equals \texttt{(list
  'man 'the 'is)}, and \texttt{word-tokens} equals \texttt{(list 'the
  'man 'is 'is)}. Then the function would return \texttt{(list 1 1
  2)}, corresponding to the number of times \texttt{'man},
\texttt{'the}, and \texttt{'is} occur in \texttt{word-tokens}.

\begin{lstlisting}
(defn get-word-counts [vocab word-tokens]
  (let [count-word (fn [w] 
                     (get-count-of-word w word-tokens 0))]
    (map count-word vocab)))
\end{lstlisting}

\paragraph{Answer 2:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 3:}

Use the function \texttt{get-word-counts}, and the other variables we have
defined, to define a variable \texttt{moby-word-frequencies}. This variable
should contain the number of times each word in \texttt{moby-vocab} occurs in
\texttt{moby-word-tokens}.

In class we defined the functions \texttt{normalize}, \texttt{flip},
and \texttt{sample-categorical}. These functions are very useful for
us, and are included below.

\begin{lstlisting}
(defn flip [p]
  (if (< (rand 1) p)
    true
    false))

(defn normalize [params]
  (let [sum (apply + params)]
    (map (fn [x] (/ x sum)) params)))

(defn sample-categorical [outcomes params]
  (if (flip (first params))
    (first outcomes)
    (sample-categorical (rest outcomes) 
			(normalize (rest params)))))
\end{lstlisting}

Let's define a function that returns a particular probability
distribution, the uniform distribution. The uniform distribution is
the distribution which assigns equal probability to every possible
outcome.
  
The function \texttt{uniform-distribution} takes a single argument,
\texttt{outcomes}, which is a list of length n. The function should
return a list containing the number \texttt{1/n} repeated n times. For
example, if outcomes equals \texttt{(list 'the 'a 'every)}, then this
function will return \texttt{(list 1/3 1/3 1/3)}. This list can be
interpreted as a probability distribution over the outcomes, which
assigns equal probability to each of them.

\begin{lstlisting}
(defn create-uniform-distribution [outcomes]
  (let [num-outcomes (count outcomes)]
    (map (fn [x] (/ 1 num-outcomes))
	 outcomes)))
\end{lstlisting}

\paragraph{Answer 3:} Please see my answer in \texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 4:}

Using functions \texttt{create-uniform-distribution} and
\texttt{sample-categorical}, write a function
\texttt{sample-uniform-BOW-sentence} that takes a number \texttt{n}
and a list \texttt{vocab}, and returns a sentence of length
\texttt{n}. Each word in the sentence should be generated
independently from the uniform distribution over vocab. For example,
given \texttt{n} equal to \texttt{4} and \texttt{vocab} equal to
\texttt{(list 'the 'a 'every)}, a possible return value for this
function is \texttt{(list 'a 'the 'the 'a)}.

Note that this is a bag of words model, as defined in class. That is,
we assume every element of the list is generated independently. We
will call this the uniform bag of words model.

\paragraph{Answer 4:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 5:}

Define a function \texttt{compute-uniform-BOW-prob}, which takes two
arguments, \texttt{vocab} and \texttt{sentence}. \texttt{vocab} is the
list of all words in the vocabulary, and sentence is a list of
observed words. The function should return the probability of the
sentence according to the uniform bag of words model.

For example, if \texttt{vocab} equals \texttt{(list 'the 'a 'every)},
and sentence equals \texttt{(list 'every 'every)}, then the function
should return $\frac{1}{9}$.

\paragraph{Answer 5:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 6:}

Using \texttt{sample-uniform-BOW-sentence} and \texttt{moby-vocab},
sample a 3-word sentence from the vocabulary of our Moby Dick
corpus. This will be a sample from the uniform bag of words model for
this vocabulary. Repeat this process a number of times. For each of
these 3-word sentences, use \texttt{compute-uniform-BOW-prob} to
compute the probability of the sentence according to the uniform bag
of words model. What do you notice? Why is this true?

\paragraph{Answer 6:} All sentences are 3-words long and we are sampling from the \textbf{uniform} bag of words model(so all the words have the same probability), and the words are generated \textbf{independently}. Thus, the probability of each of these sentences generated is the product of the probability of each word in it. Thus all sentences have the same probability.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 7:}

In class we looked at a more general version of the bag of words
model, in which different words in the vocabulary can be assigned
different probabilities. We defined a function \texttt{sample-BOW-sentence},
which returns a sentence sampled from the bag of words model that we
have specified. Below we have included a slight variant of the
function which we defined in class. Previously the variables
vocabulary and probabilities were defined outside of the function. In
the current version, they are passed in as arguments. The function is
identical otherwise.

\begin{lstlisting}
(defn sample-BOW-sentence [len vocabulary probabilities]
  (if (= len 0)
    '()
    (cons (sample-categorical vocabulary probabilities)
	  (sample-BOW-sentence (- len 1) vocabulary probabilities))))
\end{lstlisting}

The function \texttt{sample-BOW-sentence} allows us to sample a
sentence given arbitrary probabilities for the words in our
vocabulary. Let's make use of this power and define a distribution
over the vocabulary which is better than the uniform distribution. We
will use the word frequencies for our Moby Dick corpus to
\emph{estimate} a better distribution.
  
Above we defined the variable \texttt{moby-word-frequencies}, which
contains the frequency of every word that occurs in our Moby Dick
corpus. Using \texttt{normalize} and \texttt{moby-word-frequencies},
define a variable \texttt{moby-word-probabilities}. This variable
should contain probabilities for every word in \texttt{moby-vocab}, in
proportion to its frequency in the text. A word which occurs 2 times
should receive twice as much probability as a word which occurs 1
time.

\paragraph{Answer 7:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 8:}

Using \texttt{sample-BOW-sentence}, sample a 3-word sentence from a
bag of words model, in which the probabilities are set to be those in
\texttt{moby-word-probabilities}. Repeat this process a number of
times, and write down the sentences that you collect through this
process.

\paragraph{Answer 8:} (throws I sword) (their the I) (get the but) (get mind or) (circulation me little)

\noindent\hrulefill %--------------------------------

\paragraph{Problem 9:}

Define a function \texttt{lookup-probability}, which takes three
arguments, \texttt{w}, \texttt{outcomes}, and
\texttt{probs}. \texttt{probs} represents a probability distribution
over the elements of \texttt{outcomes}. For example, if outcomes is
\texttt{(list 'the 'a 'every)}, then \texttt{probs} may be equal to
\texttt{(list 0.2 0.5 0.3)}. The first number in \texttt{probs} is the
probability of the first element of outcomes, the second number in
probs is the probability of the second element of outcomes, and so on.

\texttt{lookup-probability} should look up the probability of the
element \texttt{w}. For example, if \texttt{w} equals \texttt{'the},
then look-up probability should return \texttt{0.2}. If \texttt{w}
equals \texttt{'a}, then \texttt{lookup-probability} should return
\texttt{0.5}.

Below we have defined the function \texttt{product}. This function takes a list
of numbers as its argument, and returns the product of these numbers.

\begin{lstlisting}
(defn product [l]
  (apply * l))
\end{lstlisting}

\paragraph{Answer 9:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 10:}

Using \texttt{lookup-probability} and \texttt{product}, define a
function \texttt{compute-BOW-prob} which takes three arguments,
\texttt{sentence}, \texttt{vocabulary}, and
\texttt{probabilities}. The arguments \texttt{vocabulary} and
\texttt{probabilities} are used to define a bag of words model with
the associated probability distribution over vocabulary words. The
function should compute the probability of the sentence (which is a
list of words) according to the bag of words model.

This function is a generalization of the function
\texttt{compute-uniform-BOW-prob} that you defined above.

\paragraph{Answer 10:} Please see my answer in
\texttt{ps\PSnum-lastname-firstname.clj}.

\noindent\hrulefill %--------------------------------

\paragraph{Problem 11:}

In problem 8, you collected a number of 3-word sentences. These
sentences were generated from a bag of words model in which the
probabilities were set to those in \texttt{moby-word-probabilities},
which reflect the relative frequency of the words in the Moby Dick
corpus. Use \texttt{compute-BOW-prob} to compute the probability of
these sentences according to the bag of words model. How does your
answer differ from problem 6?

Choose one of the 3-word sentences that you have generated. Can you
construct a different sentence which has the same probability
according to the bag of words model? When computing the probability of
a sentence under a bag of words model, what information about the
sentence suffices to compute this probability?

\paragraph{Answer 11:} It is clear that the probabilities of the sentences generated in Problem8 are greater than probabilities of sentences sampled in Problem6. sentence chosen: (get the but), and probability computed using \texttt{compute-BOW-prob} is 20/9129329. \newline Yes, it is possible to construct another sentence that has the same probability. Since according to \texttt{moby-word-probabilities} "get" has the same probability as "off", the sentence (off the but) would have the same probability as (get the but). Because the words are generated independently, to compute the probability of a sentence, we need to know the probability of each of the vocabularies that made up the sentence.    


\end{document}
